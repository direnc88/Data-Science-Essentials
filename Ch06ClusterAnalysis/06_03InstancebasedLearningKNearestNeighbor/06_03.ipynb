{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](Header__0004_6.png \"Header\")\n",
    "___\n",
    "# Chapter 6 - Cluster Analysis\n",
    "## Segment 3 - Instance-based learning w/ k-Nearest Neighbor\n",
    "#### Setting up for classification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K Nearest Neighbor - KNN is a supervised classifier that memorizes observations from within a labeled test set \n",
    "# to predict classification  lables for new, unlabeled observations. \n",
    "# KNN predictions based on how similar training observations are to the nw, incoming observations. The more similar\n",
    "# the observation's balues, the more likely they will be classified with the same label. \n",
    "# \n",
    "# Use cases:\n",
    "# - Stock price prediction\n",
    "# - recommendation systems\n",
    "# - Credit risk analysis\n",
    "# - Predictive trip planning\n",
    "#\n",
    "# Assumptions:\n",
    "# - Dataset has little noise\n",
    "# - dataset is labeled\n",
    "# - dataset only contains relevant features\n",
    "# - dataset has distinguishable subgroups\n",
    "# - Avoid using KNN on large datasets. It will probably take too long. \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import urllib\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#just setting the plotting parameters. \n",
    "np.set_printoptions(precision=4, suppress=True) \n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 7, 4\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Splitting your data into test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the mtcars dataset. \n",
    "address = 'C:/Users/Lillian Pierson/Desktop/Exercise Files/Ch06/06_03/mtcars.csv'\n",
    "cars = pd.read_csv(address)\n",
    "cars.columns = ['car_names','mpg','cyl','disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
    "#we'll be using these variables as the predictive weight to predict the transmission of the model. \n",
    "#mpg, disp, hp, and weight. we'll also use values at the end so that we're accessing the values in the columns. \n",
    "X_prime = cars.ix[:,(1,3,4,6)].values\n",
    "#setting our target variables. Am (automatic/manual)\n",
    "y = cars.ix[:,9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaling our dataset. \n",
    "X = preprocessing.scale(X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use scikit learns train/test function so that we can split our dataset into a test set and a train set. \n",
    "#output is x test, x train, y train, y test. \n",
    "#size tells us that 33% of our data should go into the test dataset and the rest will be used to train. \n",
    "#random state is the seed so that we get the same result each time. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training your model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "#instantiating a k nearest neighbors object and calling it clf. \n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "\n",
    "#calling the fit method on this data and passing in the training data. x train is the training data, y train is \n",
    "# the target variable. \n",
    "clf.fit(X_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating your model's predictions against the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      1.00      0.83         5\n",
      "          1       1.00      0.67      0.80         6\n",
      "\n",
      "avg / total       0.87      0.82      0.82        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming the y test set to y expect to make this easier. \n",
    "y_expect = y_test\n",
    "\n",
    "# y pred is going to contain the labels that the model predicts for the y label. \n",
    "#calling the predict method on it and passing in the x test dataset. \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# classification support method will score the model. \n",
    "print(metrics.classification_report(y_expect, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recall is a measure of a model's completeness. These results are telling us that of all the points labeled 1\n",
    "# only 67% of the results were truly relevent and in the entire dataset 82% of the results that were returned were\n",
    "# truly relevent. \n",
    "# \n",
    "#\n",
    "# hihg precision + low recall = few results returned, but many of the label predicitons returned were correct. \n",
    "# High accuracy, but low completion. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
